{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear\n",
    "\n",
    "<div class=\"admonition danger\">\n",
    "    <p class=\"admonition-title\">DRAFT</p>\n",
    "    <p style=\"padding-top: 1em\">\n",
    "        This page is a work in progress and is subject to change at any moment.\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "RANDOM_STATE = 32665\n",
    "\n",
    "CSV_PATH = \"https://gitlab.com/oasci/courses/pitt/biosc1540-2024s/-/raw/main/biosc1540/files/csv/mushrooms.csv\"\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "df_X = df.loc[:, df.columns != \"class\"]\n",
    "df_y = df[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Throw it into sklearn\n",
    "\n",
    "TODO: Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_X_encoded = df_X.apply(label_encoder.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_X_encoded, df_y, test_size=0.3, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           e       0.94      0.96      0.95      1276\n",
      "           p       0.96      0.94      0.95      1162\n",
      "\n",
      "    accuracy                           0.95      2438\n",
      "   macro avg       0.95      0.95      0.95      2438\n",
      "weighted avg       0.95      0.95      0.95      2438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "### Precision\n",
    "\n",
    "Precision is a crucial metric in assessing the accuracy of positive predictions made by a classification model, particularly in binary classification scenarios.\n",
    "\n",
    "In the context of distinguishing between edible and poisonous mushrooms, the paragraph emphasizes that the precision for both classes is high.\n",
    "This implies that when the model predicts a mushroom to be either edible or poisonous, it is typically correct.\n",
    "Essentially, the model excels in accurately identifying mushrooms belonging to a specific class, showcasing its reliability in making positive predictions.\n",
    "This high precision is especially important in situations where the consequences of misclassifying an observation could be significant.\n",
    "In the case of mushroom classification, where misidentifying an edible mushroom as poisonous (or vice versa) could have serious implications, the model's ability to maintain high precision instills confidence in the accuracy of its positive predictions.\n",
    "\n",
    "### Recall\n",
    "\n",
    "Recall, also known as sensitivity, gauges the model's proficiency in capturing all instances of the actual positive class.\n",
    "The ratio is calculated by dividing the number of correctly predicted positive observations by the total number of observations belonging to the actual positive class.\n",
    "\n",
    "In the context of mushroom classification, the paragraph underscores that both classes (edible and poisonous) exhibit high recall values. This signifies that the model excels in identifying a vast majority of instances for both types of mushrooms.\n",
    "In simpler terms, when there is an edible or poisonous mushroom present, the model is effective at recognizing and correctly labeling it.\n",
    "This strong recall suggests that the model has a robust ability to capture positive cases, providing confidence in its effectiveness in identifying instances of both edible and poisonous mushrooms with a high degree of accuracy.\n",
    "\n",
    "### Precision vs. recall\n",
    "\n",
    "Recall focuses on the model's ability to capture all actual positive instances, aiming to minimize false negatives.\n",
    "It's about not missing relevant cases.\n",
    "Precision focuses on the accuracy of positive predictions, aiming to minimize false positives. It's about ensuring that when the model predicts positive, it's likely to be correct.\n",
    "\n",
    "### F1-score\n",
    "\n",
    "The F1-score is a valuable metric that encapsulates the performance of a classification model by taking into account both precision and recall.\n",
    "Computed as the harmonic mean of these two metrics, the F1-score provides a balanced measure that is especially useful when there's an imbalance between the classes.\n",
    "\n",
    "$$\n",
    "F1 = 2 \\frac{Precision * Recall}{Precision + Recall}\n",
    "$$\n",
    "\n",
    "The harmonic mean, employed in the F1-score calculation, places more weight on lower values, making it sensitive to imbalances in precision and recall.\n",
    "This sensitivity is crucial in scenarios where one class significantly outnumbers the other.\n",
    "In such cases, relying solely on accuracy might be misleading, as a model could achieve high accuracy by favoring the majority class.\n",
    "The F1-score, with its ability to consider both false positives and false negatives, offers a more nuanced evaluation, making it a reliable choice for assessing model performance, particularly in situations with imbalanced class distributions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are all features needed?\n",
    "\n",
    "TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cap_shape: -0.057\n",
      "cap_surface: 0.442\n",
      "cap_color: -0.043\n",
      "bruises: -0.837\n",
      "odor: -0.520\n",
      "gill_attachment: -1.663\n",
      "gill_spacing: -6.438\n",
      "gill_size: 7.080\n",
      "gill_color: -0.105\n",
      "stalk_shape: 0.108\n",
      "stalk_root: -1.608\n",
      "stalk_surface_above_ring: -4.212\n",
      "stalk_surface_below_ring: -0.323\n",
      "stalk_color_above_ring: -0.142\n",
      "stalk_color_below_ring: -0.049\n",
      "veil_type: 0.000\n",
      "veil_color: 6.114\n",
      "ring_number: 1.404\n",
      "ring_type: 0.792\n",
      "spore_print_color: -0.206\n",
      "population: -0.296\n",
      "habitat: 0.059\n"
     ]
    }
   ],
   "source": [
    "feature_names = model.feature_names_in_\n",
    "feature_coeffs = model.coef_[0]\n",
    "\n",
    "for feature_name, feature_coef in zip(model.feature_names_in_, model.coef_[0]):\n",
    "    print(f\"{feature_name}: {feature_coef:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gill_attachment' 'stalk_surface_above_ring' 'veil_color' 'gill_spacing'\n",
      " 'gill_size']\n"
     ]
    }
   ],
   "source": [
    "idx_sort = np.argsort(np.abs(feature_coeffs))\n",
    "\n",
    "features_top = feature_names[idx_sort[-5:]]\n",
    "print(features_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           e       0.92      0.96      0.94      1276\n",
      "           p       0.96      0.91      0.93      1162\n",
      "\n",
      "    accuracy                           0.94      2438\n",
      "   macro avg       0.94      0.94      0.94      2438\n",
      "weighted avg       0.94      0.94      0.94      2438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train[features_top], y_train)\n",
    "\n",
    "y_pred = model.predict(X_test[features_top])\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['veil_type' 'cap_color' 'stalk_color_below_ring' 'cap_shape' 'habitat'\n",
      " 'gill_color' 'stalk_shape' 'stalk_color_above_ring' 'spore_print_color'\n",
      " 'population']\n"
     ]
    }
   ],
   "source": [
    "features_bottom = feature_names[idx_sort[:10]]\n",
    "print(features_bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           e       0.83      0.85      0.84      1276\n",
      "           p       0.83      0.81      0.82      1162\n",
      "\n",
      "    accuracy                           0.83      2438\n",
      "   macro avg       0.83      0.83      0.83      2438\n",
      "weighted avg       0.83      0.83      0.83      2438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train[features_bottom], y_train)\n",
    "\n",
    "y_pred = model.predict(X_test[features_bottom])\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(classification_rep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biosc1540-2024s-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
