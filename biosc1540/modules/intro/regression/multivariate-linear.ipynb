{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate linear\n",
    "\n",
    "Multivariate linear regression is a statistical method used for modeling the relationship between multiple independent variables and a single dependent variable.\n",
    "In contrast to [univariate linear regression](../univariate-linear), which involves only one independent variable, multivariate linear regression considers several simultaneously.\n",
    "The goal is to create a linear equation that best fits the observed data, allowing for predictions or explanations of the dependent variable based on the values of the independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, let's load our CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = \"https://gitlab.com/oasci/courses/pitt/biosc1540-2024s/-/raw/main/biosc1540/files/csv/advertising-data.csv\"\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of multivariate regression, we collect all of our independent variables in one dataframe called `df_features` and our dependent variable in `df_targets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = \"Product_Sold\"\n",
    "\n",
    "df_features = df.drop(columns=[target_column], inplace=False)\n",
    "df_targets = df[target_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to convert the dataframe to NumPy arrays and reshape the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = df_targets.to_numpy().reshape(-1, 1)\n",
    "features = df_features.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear\n",
    "\n",
    "You actually use the same procedure to do multivariate regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 36.655\n",
      "Coefficients: [1.97147823 2.79786525 1.59446751 2.43283307 1.40693022 3.91183385]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X=features, y=targets)\n",
    "print(f\"Intercept: {model.intercept_[0]:.3f}\")\n",
    "print(f\"Coefficients: {model.coef_[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intercept (`reg.intercept_`) is the constant term in the linear equation.\n",
    "The intercept represents the estimated product sales when all advertising spending is zero.\n",
    "\n",
    "The coefficients (`reg.coef_`) represent the weights assigned to each advertising channel (TV, Billboards, Google Ads, Social Media, Influencer Marketing, Affiliate Marketing) in predicting product sales.\n",
    "These coefficients indicate the estimated change in product sales for a one-unit increase in each respective advertising channel, holding other variables constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome!\n",
    "We already performed a linear fit for `Social_Media` and found the coefficient to be `2.418`.\n",
    "Let's check to see what it is now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.432833068526262\n"
     ]
    }
   ],
   "source": [
    "social_media_index = df_features.columns.get_loc(\"Social_Media\")\n",
    "print(model.coef_[0][social_media_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait a second, that is slightly different than before.\n",
    "Which one is more accurate?\n",
    "\n",
    "Well, let's see what the score is of this new model and compare it against our univariate score of `0.154`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9401750192922066\n"
     ]
    }
   ],
   "source": [
    "print(model.score(X=features, y=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow!\n",
    "That is much better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In helping the company, you can use these coefficients to guide them on how each advertising channel contributes to product sales.\n",
    "For example, higher coefficients suggest a stronger positive impact on sales.\n",
    "Adjusting ad budgets based on these coefficients could optimize their advertising strategy for higher sales.\n",
    "Remember that correlation does not imply causation, so further analysis and experimentation may be needed to validate the findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "In all of our analyses, we have not been consistently normalizing our data before fitting regression models.\n",
    "This is a huge (intentional) oversight, and this raises concerns about the potential bias and misinterpretation of variable contributions in our models.\n",
    "Without normalization, features with different scales may have been influencing our regression coefficients disproportionately, leading to skewed results.\n",
    "Recognizing the importance of feature scale consistency in regression analysis, it becomes imperative for us to revisit our modeling approach and incorporate proper normalization techniques.\n",
    "By doing so, we aim to enhance the accuracy and reliability of our models, ensuring that the impact of each predictor is appropriately considered, regardless of its original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [515.9102   503.7412   518.42545  500.7092   483.258675 499.808   ]\n",
      "Stdev: [274.58593496 260.36497289 274.35957055 266.42971192 277.79795289\n",
      " 270.41370242]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean: {np.mean(features, axis=0)}\")\n",
    "print(f\"Stdev: {np.std(features, axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our data is more or less on the same scale, so we should be fine.\n",
    "However, just to play it safe, let's normalize our features using [`MinMaxScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) which scales and translates each feature individually such that it is in the given range on the training set, e.g. between zero and one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: [0.51638838 0.50430195 0.51156115 0.49673347 0.48294264 0.50269973]\n",
      "Stdev: [0.2753956  0.26254674 0.2787159  0.27063264 0.27805933 0.27569604]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "features_normed = scaler.fit_transform(features)\n",
    "\n",
    "print(f\"Mean: {np.mean(features_normed, axis=0)}\")\n",
    "print(f\"Stdev: {np.std(features_normed, axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn provides another scaler, called [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) that removes the mean and scaling to unit variance.\n",
    "\n",
    "How do you choose which one to use?\n",
    "In practice, it's often a good idea to try both scalers and observe the impact on your model's performance through cross-validation.\n",
    "The choice between the two depends on the characteristics of your data and the assumptions of the models you are using.\n",
    "\n",
    "**`StandardScaler`**\n",
    "\n",
    "-   **When the distribution of the features is approximately Gaussian (normal):**\n",
    "    `StandardScaler` assumes that your data follows a normal distribution. If your features are roughly normally distributed, using `StandardScaler` is a good choice.\n",
    "-   **When you are using models that rely on distances between data points:**\n",
    "    Models like k-nearest neighbors (KNN) and support vector machines (SVM) that involve distance calculations may perform better with standardized features.\n",
    "-   **When dealing with algorithms that assume zero-mean and unit-variance features:**\n",
    "    Some algorithms, like principal component analysis (PCA), assume that the features have zero mean and unit variance.\n",
    "    Standardizing the features using `StandardScaler` ensures that these assumptions are met.\n",
    "\n",
    "**`MinMaxScaler`**\n",
    "\n",
    "-   **When your features have varying scales and you want to preserve the original distribution:**\n",
    "    Use `MinMaxScaler` when you have features with different scales, and you want to scale them to a specific range (e.g., [0, 1]) while preserving the original distribution.\n",
    "-   **For algorithms sensitive to the scale of input features:**\n",
    "    Some algorithms, like neural networks and gradient-based optimization methods, can benefit from input features that are on a similar scale.\n",
    "    In such cases, using `MinMaxScaler` might be a good choice.\n",
    "-   **When you want to interpret the scaled features in the original domain:**\n",
    "    If you need to interpret the scaled features in the context of the original data range, `MinMaxScaler` is more suitable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial\n",
    "\n",
    "\n",
    "[`PolynomialFeatures`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) will convert our individual features into all possible polynomial combinations.\n",
    "For example, if we had two features $a$ and $b$, `PolynomialFeatures` would return the features $a$, $b$, $a^2$, $ab$, and $b^2$.\n",
    "\n",
    "Let's proceed with our example data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n features: 6\n",
      "n poly features: 28\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_degree = 2\n",
    "\n",
    "# poly_featurizer is a class that will convert features\n",
    "poly_featurizer = PolynomialFeatures(degree=poly_degree)\n",
    "\n",
    "features_poly = poly_featurizer.fit_transform(features_normed)\n",
    "\n",
    "print(f\"n features: {features_normed.shape[1]}\")\n",
    "print(f\"n poly features: {features_poly.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we went from 6 to 28 features.\n",
    "Curious as to what they are?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' 'x0' 'x1' 'x2' 'x3' 'x4' 'x5' 'x0^2' 'x0 x1' 'x0 x2' 'x0 x3' 'x0 x4'\n",
      " 'x0 x5' 'x1^2' 'x1 x2' 'x1 x3' 'x1 x4' 'x1 x5' 'x2^2' 'x2 x3' 'x2 x4'\n",
      " 'x2 x5' 'x3^2' 'x3 x4' 'x3 x5' 'x4^2' 'x4 x5' 'x5^2']\n"
     ]
    }
   ],
   "source": [
    "feature_names = poly_featurizer.get_feature_names_out()\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Original features: $x_1, \\; x_2, \\; x_3, \\; x_4, \\; x_5, \\; x_6$\n",
    "2. Squared features: $x_1^2, \\; x_2^2, \\; x_3^2, \\; x_4^2, \\; x_5^2, \\; x_6^2$\n",
    "3. Product features: $x_1x_2, \\; x_1x_3, \\; x_1x_4, \\; x_1x_5, \\; x_1x_6, \\; x_2x_3, \\; x_2x_4, \\; x_2x_5, \\; x_2x_6, \\; x_3x_4, \\; x_3x_5, \\; x_3x_6, \\; x_4x_5, \\; x_4x_6, \\; x_5x_6$\n",
    "\n",
    "We have already lost a lot of interpretability, as it is difficult to discern each feature's individual contributions.\n",
    "Let's proceed anyway.\n",
    "\n",
    "What is that `1` in there?\n",
    "Well, that is the bias and this allows you to have a non-zero intercept.\n",
    "This means we do not want our `LinearRegression` to fit another intercept, so we have to use `fit_intercept=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression(fit_intercept=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression(fit_intercept=False)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression(fit_intercept=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_poly = LinearRegression(fit_intercept=False)\n",
    "\n",
    "# Fit the model with the polynomial features\n",
    "model_poly.fit(features_poly, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 1.135e+02\n",
      "x0: 2.159e+03\n",
      "x1: 3.406e+03\n",
      "x2: 1.150e+03\n",
      "x3: 2.232e+03\n",
      "x4: 1.096e+03\n",
      "x5: 3.952e+03\n",
      "x0^2: -3.152e+02\n",
      "x0 x1: -3.633e+02\n",
      "x0 x2: 2.983e+02\n",
      "x0 x3: -6.785e+01\n",
      "x0 x4: 4.945e+01\n",
      "x0 x5: 3.729e+02\n",
      "x1^2: 1.948e+02\n",
      "x1 x2: -4.661e+02\n",
      "x1 x3: -3.036e+02\n",
      "x1 x4: -1.073e+02\n",
      "x1 x5: -3.897e+02\n",
      "x2^2: 2.727e+02\n",
      "x2 x3: 2.408e+02\n",
      "x2 x4: 2.480e+02\n",
      "x2 x5: -2.628e+01\n",
      "x3^2: 7.360e+01\n",
      "x3 x4: 2.979e+02\n",
      "x3 x5: -1.230e+01\n",
      "x4^2: -4.403e+01\n",
      "x4 x5: 1.977e+02\n",
      "x5^2: -1.815e+02\n"
     ]
    }
   ],
   "source": [
    "for feature_name, coeff in zip(feature_names, model_poly.coef_[0]):\n",
    "    print(f\"{feature_name}: {coeff:.3e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare our model score to the standard linear regression of `0.94018`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly score: 0.94243\n"
     ]
    }
   ],
   "source": [
    "score_poly = model_poly.score(X=features_poly, y=targets)\n",
    "print(f\"Poly score: {score_poly:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our polynomial model has a slightly better $R^2$ score, but its not substantial.\n",
    "However, now we do not have an easily interpretable model to recommend our business."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge\n",
    "\n",
    "Ridge regression, also known as Tikhonov regularization or $L2$ regularization, is a linear regression technique that introduces a regularization term to the linear regression objective function.\n",
    "The primary goal of ridge regression is to address the issue of multicollinearity in linear regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective function\n",
    "\n",
    "\n",
    "In ridge regression, a regularization term is added to this objective function.\n",
    "The new objective function becomes:\n",
    "\n",
    "$$\n",
    "\\text{minimize} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\alpha \\sum_{j=1}^{p} \\beta_j^2\n",
    "$$\n",
    "\n",
    "Here:\n",
    "\n",
    "-   $n$ is the number of observations.\n",
    "-   $p$ is the number of predictors (features).\n",
    "-   $y_i$​ is the actual value of the dependent variable for the ii-th observation.\n",
    "-   $\\hat{y}_i$​ is the predicted value of the dependent variable for the ii-th observation.\n",
    "-   $\\alpha$ is the regularization parameter, controlling the strength of regularization.\n",
    "-   $\\beta_j$ represents the coefficients of the linear regression model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "\n",
    "\n",
    "**Not Suitable for Feature Selection**\n",
    "\n",
    "One of the primary limitations of ridge regression lies in its inability to perform feature selection.\n",
    "Unlike some other regularization techniques, ridge regression retains all features in the model, making it less suitable for scenarios where variable selection is a critical requirement.\n",
    "\n",
    "**Interpretability Challenges**\n",
    "\n",
    "While ridge regression addresses multicollinearity, it does so at the expense of straightforward interpretability.\n",
    "The regularization term introduces a level of complexity to coefficient interpretation, as the coefficients are shrunk towards zero.\n",
    "This departure from the clear interpretability of standard linear regression should be acknowledged.\n",
    "\n",
    "**Dependency on Scaling**\n",
    "\n",
    "The performance of ridge regression is influenced by the scale of the variables.\n",
    "Rescaling or standardizing the features is often necessary to ensure effective regularization.\n",
    "Failure to do so can result in unequal penalization of coefficients, impacting the model's stability.\n",
    "\n",
    "**No Sparsity in Coefficients**\n",
    "\n",
    "Unlike some regularization methods, such as LASSO (L1 regularization), ridge regression does not lead to exact zero coefficients.\n",
    "It shrinks coefficients towards zero but retains all features in the model.\n",
    "If sparsity is a critical consideration, alternative regularization methods may be more appropriate.\n",
    "\n",
    "**Model Complexity**\n",
    "\n",
    "Ridge regression introduces a level of model complexity, with the choice of the regularization parameter ($\\alpha$) playing a pivotal role.\n",
    "Selecting an optimal $\\alpha$ value often involves techniques like cross-validation, adding an additional layer of complexity to model tuning.\n",
    "\n",
    "**Assumption of Linearity**\n",
    "\n",
    "Similar to standard linear regression, ridge regression assumes a linear relationship between the independent and dependent variables.\n",
    "If the true relationship is significantly nonlinear, ridge regression may not capture the underlying patterns accurately.\n",
    "\n",
    "**Limited Handling of Multicollinearity**\n",
    "\n",
    "While ridge regression is effective in mitigating multicollinearity, it may not completely eliminate the issue.\n",
    "In cases of severe multicollinearity, additional techniques or data preprocessing methods may be necessary.\n",
    "\n",
    "**Sensitivity to Outliers**\n",
    "\n",
    "Ridge regression exhibits reduced sensitivity to outliers compared to standard linear regression, yet extreme values can still influence the regularization process and impact the resulting coefficients.\n",
    "Practitioners should exercise caution in the presence of outliers.\n",
    "\n",
    "**Not a Panacea**\n",
    "\n",
    "It is crucial to recognize that ridge regression is not a universal solution.\n",
    "Its effectiveness depends on the specific characteristics of the data and the objectives of the analysis.\n",
    "Careful consideration of alternative regularization techniques may be warranted in certain scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 372.860\n",
      "Coefficients: [1906.99723949 2674.42209007 1513.78849822 2315.60502501 1348.95403981\n",
      " 3701.14415754]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model_ridge = Ridge(alpha=1.0)\n",
    "model_ridge.fit(X=features_normed, y=targets)\n",
    "\n",
    "print(f\"Intercept: {model_ridge.intercept_[0]:.3f}\")\n",
    "print(f\"Coefficients: {model_ridge.coef_[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9390368174983559\n"
     ]
    }
   ],
   "source": [
    "print(model_ridge.score(X=features_normed, y=targets))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biosc1540-2024s-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
